# -*- coding: utf-8 -*-
"""Proyek Satu

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qql6H9886HDGHGDzTIZmTQadu9NWcV-D

# Import Library & Module
"""

#--Import Library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#--Preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

#--Modelling
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV


#--Evaluasi
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""# Data Wrangling

## Gathering Data
"""

games_df = pd.read_csv('vgsales.csv')
if games_df is not None and not games_df.empty:
    print('Dataset berhasil dibaca')
else:
    print('Dataset gagal dibaca')

"""## Assesing Data"""

games_df.head()

games_df.tail()

games_df.info()

games_df.describe()

games_df.isna().sum()

print("Jumlah duplikasi: ", games_df.duplicated().sum())

"""**Insight**


Dataset ini termasuk besar berdasarkan jumlah datanya. Berdasarkan hasil di atas dapat dilihat bahwa mayoritas tipe data kolom adalah float, disusul dengan object dan int. Terdapat 2 kolom yang memiliki nilai null yaitu kolom 'year' dan 'publisher'. Untuk kolom 'year', perlu dilakukan analisis lebih lanjut untuk menentukan apakah akan dilakukan imputasi secara random atau penghapusan. Sementara itu, untuk kolom 'publisher', kemungkinan akan dilakukan imputasi dengan nilai "indie", namun tetap akan dilakukan analisis lebih lanjut sebelum mengambil keputusan.

# Exploratory Data Analysis (EDA)
"""

#Banyak game per platform (10 terbanyak)
top_platform = games_df['Platform'].value_counts().head(10)
sns.barplot(x=top_platform.index, y=top_platform.values)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.title('Top 10 Platform by Number of Games')
plt.show()

#Banyak game per genre

games_genre = games_df['Genre'].value_counts()
sns.barplot(x=games_genre.index, y=games_genre.values)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.title('Genres by Number of Games')
plt.show()

#Banyak game per publisher
top_publishers = games_df['Publisher'].value_counts().head(10)
sns.barplot(x=top_publishers.index, y=top_publishers.values)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.title('Top 10 Publishers by Number of Games')
plt.show()

games_df[games_df['Publisher'].isnull()][['Name', 'Platform', 'Genre', 'Year', 'Global_Sales']].head(10)

sales_cols = ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']
sales_melted = games_df[sales_cols].melt(var_name='Region', value_name='Sales')

plt.figure(figsize=(12, 6))
sns.boxplot(x='Region', y='Sales', data=sales_melted, palette='Set2')
plt.title('Distribusi Penjualan per Wilayah dan Global (dalam Jutaan Unit)')
plt.xlabel('Wilayah')
plt.ylabel('Sales')
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.heatmap(games_df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title('Heatmap Korelasi Fitur Numerik')
plt.show()

# 10 Platform dengan penjualan terbaik Global
top_platform_sales = games_df.groupby('Platform')['Global_Sales'].sum().sort_values(ascending=False).head(10)
plt.figure(figsize=(10, 6))
sns.barplot(x=top_platform_sales.values, y=top_platform_sales.index, palette='viridis')
plt.title('Top 10 Platform berdasarkan Total Global Sales')
plt.xlabel('Total Global Sales (juta unit)')
plt.ylabel('Platform')
plt.show()

# Rata-rata penjualan global per genre
genre_sales = games_df.groupby('Genre')['Global_Sales'].mean().sort_values(ascending=False)
plt.figure(figsize=(10,6))
sns.barplot(x=genre_sales.values, y=genre_sales.index, palette='magma')
plt.title('Rata-rata Penjualan Global per Genre')
plt.xlabel('Rata-rata Global Sales (juta unit)')
plt.ylabel('Genre')
plt.show()

"""**Insight**

- **Nintendo DS, PlayStation 2, dan PlayStation 3** menjadi tiga platform dengan jumlah game terbanyak dalam dataset.
- Genre **Action, Adventure, dan Misc (Miscellaneous)** menjadi tiga kategori dengan jumlah game terbanyak.
- **Electronic Arts (EA)** menjadi publisher dengan judul game terbanyak.
- Posisi kedua dan ketiga diisi oleh **Activision** dan **Bandai Namco**.
- Publisher dengan data kosong awalnya dipertimbangkan untuk diimputasi sebagai "*indie*", namun setelah analisis lebih lanjut, data tersebut akan **dihapus** karena sebagian besar merupakan game adaptasi dari franchise TV.
- Terdapat **outlier** pada data penjualan global (nilai ekstrem di sebelah kanan distribusi), yang wajar mengingat beberapa game memiliki popularitas dan penjualan jauh di atas rata-rata.
- Data penjualan kemungkinan akan **dinormalisasi** untuk analisis lebih lanjut.
- Terlihat korelasi **kuat** antara penjualan di Amerika Utara dengan penjualan global, yang menunjukkan bahwa pasar Amerika Utara memiliki pengaruh signifikan terhadap kesuksesan game secara global.
- Platform konsol tradisional seperti **PS2, PS3, Xbox 360, PS4, PS, dan Wii** mendominasi daftar platform dengan game-game penjualan tertinggi.
- Rata-rata penjualan tertinggi per genre didominasi oleh kategori **Platform**(Super Mario Series, Donkey Kong), diikuti oleh **Shooting**, dan **Role-Playing (RPG)** di posisi ketiga.

## Explanatory Analysis

### Perbandingan penjualan tiap regional pada 6 platform teratas
"""

#Perbandingan Penjualan Regional pada 6 platform teratas
regional_sales = games_df.groupby('Platform')[['NA_Sales', 'EU_Sales', 'JP_Sales']].sum()
top_platforms = regional_sales.sum(axis=1).sort_values(ascending=False).head(6).index
regional_sales = regional_sales.loc[top_platforms]

regional_sales.plot(kind='bar', stacked=True, figsize=(12, 6), colormap='Set2')
plt.title('Perbandingan Penjualan Regional (NA, EU, JP) pada 6 Platform Teratas')
plt.xlabel('Platform')
plt.ylabel('Total Sales (juta unit)')
plt.legend(title='Region')
plt.tight_layout()
plt.show()

"""### Pertumbuhan Penjualan game Per Genre (2000-2010)"""

df_2000s = games_df[(games_df['Year'] >= 2000) & (games_df['Year'] <= 2010)]

genre_year_sales = df_2000s.groupby(['Year', 'Genre'])['Global_Sales'].sum().reset_index()

pivot_genre = genre_year_sales.pivot(index='Year', columns='Genre', values='Global_Sales').fillna(0)

plt.figure(figsize=(12, 6))
pivot_genre.plot(figsize=(14, 6), cmap='tab20', linewidth=2)
plt.title('Pertumbuhan Penjualan Game per Genre (2000‚Äì2010)')
plt.xlabel('Tahun')
plt.ylabel('Total Global Sales (juta unit)')
plt.legend(title='Genre', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""Dapat dilihat dilihat terdapat pertumbuhan melonjak untuk genre adventure pada 2006"""

adventure_2006 = games_df[(games_df['Year'] == 2006) & (games_df['Genre'] == 'Adventure')]

adventure_2006_sorted = adventure_2006.sort_values(by='Global_Sales', ascending=False)

adventure_2006_sorted[['Name', 'Platform', 'Publisher', 'Global_Sales']].head(10)

top_diff_games = games_df[['Name', 'NA_Sales', 'JP_Sales']].dropna()
top_diff_games = top_diff_games.loc[
    abs(top_diff_games['NA_Sales'] - top_diff_games['JP_Sales']).sort_values(ascending=False).index
].head(5)

top_diff_games.set_index('Name')[['NA_Sales', 'JP_Sales']].plot(
    kind='bar', figsize=(10, 6), colormap='Accent'
)
plt.title('Top 5 Game dengan Selisih Penjualan Terbesar (NA vs JP)')
plt.ylabel('Sales (juta unit)')
plt.xlabel('Game')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""Insight

- **Amerika Utara mendominasi** penjualan game di semua platform.
- Game-game **Xbox memiliki performa buruk di pasar Jepang**, menunjukkan **minat pasar yang rendah** terhadap konsol ini di wilayah tersebut.
- **Terdapat kesenjangan signifikan** antara penjualan di **Amerika Utara dan Jepang** untuk hampir semua platform, menegaskan ketimpangan distribusi pasar.
- Tiap genre menunjukkan **pola pertumbuhan yang unik dan menarik**.
- Beberapa genre, meskipun berbeda dalam jumlah total game, menunjukkan **fluktuasi pertumbuhan yang sangat mirip**.
- **Tahun 2006 menjadi titik penting**, dengan:
  - **Peningkatan signifikan** pada genre **Adventure** dan **Role-Playing**.
  - **Penurunan tajam** pada genre **Action** dan **Shooter**.
- Genre **Adventure** dan **Role-Playing** memiliki **pola pertumbuhan yang sangat mirip sepanjang waktu**, mengindikasikan **faktor pasar yang sama** mungkin mempengaruhi keduanya.
- **Kesenjangan besar** antara penjualan di **Amerika Utara dan Jepang** terlihat jelas di mayoritas game.
- **Pasar Amerika Utara** terbukti sebagai **pasar terbesar dan paling berpengaruh** terhadap total penjualan global game.

# Data Preprocessing

### Menghapus missing values
"""

#hapus baris yang memiliki tahun kosong
games_df = games_df.dropna(subset=['Year'])

#hapus baris game yang tidak memiliki publisher
games_df = games_df.dropna(subset=['Publisher'])

print(games_df.isnull().sum())

"""### Encoding fitur kategorikal

disini saya mengencoding fitur kategorikal dikarenakan model seperti linear regression hanya bisa membaca fitur numerik
"""

games_df = pd.get_dummies(games_df, columns=['Genre', 'Platform'], drop_first=True)

"""lalu untuk publisher karena banyaknya publisher. dan juga demi mencegah high-dimensionality saya memutusukan untuk mapping semua publisher yang memiliki judul dibawah 150 game akan dijadikan "other"
"""

publisher_counts = games_df['Publisher'].value_counts()
top_publishers = publisher_counts[publisher_counts > 150].index
games_df['Publisher_grouped'] = games_df['Publisher'].apply(lambda x: x if x in top_publishers else 'Other')
games_df = pd.get_dummies(games_df, columns=['Publisher_grouped'], drop_first=True)
games_df = games_df.drop('Publisher', axis=1)

games_df.head()

"""**Drop Kolom yang tidak dibutuhkan**

sebelum lanjut ke tahap selanjutnya kita akan drop Rank dan Name karena tidak diperlukan dalam training nantinya
"""

encoded_games_df = games_df.drop(['Rank', 'Name'], axis=1)

encoded_games_df.head()

"""lalu melakukan log transform. hal ini dilakukan karena seperti yang terlihat bahwa data sales memiliki outlier yang banyak dan cukup tinggi di beberapa game"""

for col in ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']:
    encoded_games_df[f'Log_{col}'] = np.log1p(encoded_games_df[col])

encoded_games_df.head()

encoded_games_df.describe()

scaler = StandardScaler()
encoded_games_df[['Year', 'Log_NA_Sales', 'Log_EU_Sales', 'Log_JP_Sales', 'Log_Other_Sales']] = scaler.fit_transform(
    encoded_games_df[['Year', 'Log_NA_Sales', 'Log_EU_Sales', 'Log_JP_Sales', 'Log_Other_Sales']]
)

encoded_games_df.head()

encoded_games_df.describe()

"""kenapa saya memutuskan untuk membuat kolom baru pada log transformasi hal ini diperlukan agar memudahkan dalam proses pembandingann, prediksi dan visualisasi setelah hasil prediksi"""

log_sales_cols = ['Log_NA_Sales', 'Log_EU_Sales', 'Log_JP_Sales', 'Log_Other_Sales', 'Log_Global_Sales']

sales_melted = encoded_games_df[log_sales_cols].melt(var_name='Region', value_name='Sales')

plt.figure(figsize=(12, 6))
sns.boxplot(x='Region', y='Sales', data=sales_melted, palette='Set2')
plt.title('Distribusi Penjualan per Wilayah dan Global (dalam Jutaan Unit) ter Skala dan Transformasi')
plt.xlabel('Wilayah')
plt.ylabel('Sales')
plt.tight_layout()
plt.show()

encoded_games_df.shape

"""## Split Dataset"""

X = encoded_games_df.drop(columns=['Global_Sales','Log_Global_Sales'])

y = encoded_games_df['Log_Global_Sales']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""# Modelling

### Fungsi Evaluasi
"""

def evaluate_model(model, X_test, y_test, log_transformed=True):

    y_pred = model.predict(X_test)

    if log_transformed:
        y_pred = np.expm1(y_pred)
        y_test = np.expm1(y_test)

    mae = mean_absolute_error(y_test, y_pred)
    rmse = mean_squared_error(y_test, y_pred)  # pastikan ini dari sklearn
    r2 = r2_score(y_test, y_pred)

    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}

"""## Linear Regression"""

base_model = LinearRegression()
base_model.fit(X_train, y_train)

results = {}
results['Linear Regression'] = evaluate_model(base_model, X_test, y_test)

"""## Random Forest & XGBoost"""

param_grids = {
    'Random Forest': {
        'n_estimators': [100, 200],
        'max_depth': [10, 20],
        'min_samples_split': [2, 5]
    },
    'XGBoost': {
        'n_estimators': [100, 200],
        'max_depth': [3, 6],
        'learning_rate': [0.1, 0.2]
    }
}

models = {
    'Random Forest': RandomForestRegressor(random_state=42),
    'XGBoost': XGBRegressor(random_state=42, verbosity=0)
}

for name, model in models.items():
    print(f"üîç Tuning {name}...")
    grid = GridSearchCV(
        estimator=model,
        param_grid=param_grids[name],
        scoring='neg_root_mean_squared_error',
        cv=3,
        n_jobs=-1,
        verbose=1
    )
    grid.fit(X_train, y_train)

    best_model = grid.best_estimator_
    print(f"‚úÖ Best params for {name}: {grid.best_params_}")

    results[name] = evaluate_model(best_model, X_test, y_test)

"""Insight dari Pemilihan Model

- Saya menggunakan **tiga model regresi** dalam proyek ini, yaitu:
  - **Linear Regression** (sebagai baseline)
  - **Random Forest Regressor**
  - **XGBoost Regressor**

- **Linear Regression** dipilih sebagai baseline karena model ini:
  - Merupakan model regresi paling sederhana dan mudah diinterpretasikan.
  - Cepat dalam pelatihan dan evaluasi.
  - Digunakan sebagai acuan awal untuk menilai apakah model yang lebih kompleks memberikan peningkatan performa yang signifikan.

- **Random Forest** dan **XGBoost** dipilih karena mempertimbangkan karakteristik data, yaitu:
  - Dataset memiliki banyak fitur kategorikal (seperti Genre, Platform, Publisher) yang telah diencoding.
  - Terdapat fitur numerik dengan distribusi skewed dan kehadiran outlier.
  - Kedua model ini merupakan **tree-based models** yang:
    - Tidak sensitif terhadap skala fitur (tidak memerlukan scaling).
    - Robust terhadap outlier.
    - Mampu menangani relasi non-linear antar fitur.

- **XGBoost** memiliki keunggulan tambahan berupa:
  - Fitur regularisasi untuk mencegah overfitting.
  - Kemampuan mengatur kompleksitas model melalui parameter seperti `max_depth`, `learning_rate`, dan `n_estimators`.
- Dalam proses pelatihan, saya menggunakan **GridSearchCV** untuk melakukan pencarian kombinasi hyperparameter terbaik secara sistematis.  
  - Grid Search memudahkan proses eksplorasi terhadap parameter penting seperti jumlah pohon (`n_estimators`), kedalaman pohon (`max_depth`), dan learning rate.
  - Dengan pendekatan ini, model yang dihasilkan dapat mencapai performa optimal tanpa harus melakukan tuning manual yang rawan bias dan tidak efisien.

# Evaluation
"""

results_df = pd.DataFrame(results).T.sort_values(by='RMSE')
print(results_df)

"""Insight Hasil Evaluasi Model


Berdasarkan hasil evaluasi terhadap ketiga model yang diuji menggunakan data uji (test set), diperoleh metrik performa sebagai berikut:

| Model              | MAE     | RMSE    | R¬≤      |
|-------------------|---------|---------|---------|
| XGBoost            | 0.0431  | 0.5344  | 0.8404  |
| Random Forest      | 0.0397  | 0.5653  | 0.8311  |
| Linear Regression  | 0.0994  | 1.5952  | 0.5234  |

- **XGBoost** menjadi model dengan performa **terbaik secara keseluruhan**, dengan:
  - Nilai **R¬≤ sebesar 0.84**, artinya model mampu menjelaskan 84% variasi data target (Global Sales).
  - **RMSE dan MAE yang rendah**, menunjukkan bahwa prediksi yang dihasilkan cenderung akurat dan stabil.

- **Random Forest** juga menunjukkan performa yang sangat kompetitif:
  - MAE-nya bahkan sedikit **lebih rendah** dari XGBoost, menandakan prediksi rata-rata yang sangat dekat dengan nilai aktual.
  - Namun, RMSE-nya sedikit lebih tinggi, menunjukkan adanya beberapa error besar (outlier) yang memengaruhi hasil akhir.

- **Linear Regression** sebagai baseline menunjukkan performa yang **jauh lebih rendah**:
  - R¬≤ hanya **0.52**, menunjukkan bahwa model ini hanya bisa menjelaskan sekitar 52% variasi data.
  - Nilai **RMSE-nya tiga kali lebih besar** dari model tree-based, menunjukkan bahwa model ini tidak cocok untuk menangkap kompleksitas relasi antar fitur dalam data.

- Model **tree-based seperti XGBoost dan Random Forest** jauh lebih cocok untuk dataset ini dibanding model linear.
- **XGBoost** dipilih sebagai model akhir karena memberikan keseimbangan terbaik antara akurasi dan generalisasi.
"""